# Project-3
A Human-Computer Interaction software that enables the user to interact with the computer just by the means of Hand-Gestures. The proposed system uses Machine Learning based Packages like Media Pipe in which a model named “Single Shot Detector” in the package has trained to detect the desired objects from the camera stream provided by OpenCV, It captures the hand gestures and the program triggers specific mouse function accordingly. This offers the user to carry multiple Mouse functions and also to access a few System level controls, It allows us for “Left, Right, and Double Click functions”, “Scrolling”, “Cursor Navigation”, “Drag and Drop”, “Selection”, “Volume Up”, “Volume Down”, “Brightness Up”, and “Brightness Down”. It can also be used in times of pandemics, and few conditional use cases where we don’t have an option to hold a mouse such as in presentations while wearing Virtual Reality Headsets, etc. 
	In this paper, we had proposed a revolutionary model that let the users to control their machines without any physical(external).
